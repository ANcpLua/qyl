---
title: "Instrumenting Applications"
description: "Add OpenTelemetry instrumentation to send traces to qyl"
---

# Instrumenting Applications

This guide shows how to instrument your applications to send OpenTelemetry traces to qyl.

## .NET Applications

### Install packages

```bash
dotnet add package OpenTelemetry
dotnet add package OpenTelemetry.Exporter.OpenTelemetryProtocol
dotnet add package OpenTelemetry.Extensions.Hosting
```

### Configure tracing

```csharp
using OpenTelemetry;
using OpenTelemetry.Trace;
using OpenTelemetry.Resources;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddOpenTelemetry()
    .ConfigureResource(r => r
        .AddService("my-service")
        .AddAttributes(new Dictionary<string, object>
        {
            ["deployment.environment"] = "development"
        }))
    .WithTracing(tracing => tracing
        .AddAspNetCoreInstrumentation()
        .AddHttpClientInstrumentation()
        .AddOtlpExporter(opts =>
        {
            opts.Endpoint = new Uri("http://localhost:5100");
            opts.Protocol = OpenTelemetry.Exporter.OtlpExportProtocol.HttpProtobuf;
        }));
```

### Add custom spans

```csharp
using System.Diagnostics;

public class MyService
{
    private static readonly ActivitySource s_activitySource = new("MyService");

    public async Task ProcessAsync()
    {
        using var activity = s_activitySource.StartActivity("ProcessData");
        activity?.SetTag("custom.attribute", "value");

        // Your code here

        activity?.SetStatus(ActivityStatusCode.Ok);
    }
}
```

## Python Applications

### Install packages

```bash
pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp
```

### Configure tracing

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import SERVICE_NAME, Resource

resource = Resource(attributes={SERVICE_NAME: "my-python-service"})

provider = TracerProvider(resource=resource)
processor = BatchSpanProcessor(
    OTLPSpanExporter(endpoint="http://localhost:5100/v1/traces")
)
provider.add_span_processor(processor)
trace.set_tracer_provider(provider)

tracer = trace.get_tracer(__name__)
```

### Add custom spans

```python
with tracer.start_as_current_span("operation-name") as span:
    span.set_attribute("custom.key", "value")
    # Your code here
```

## Node.js Applications

### Install packages

```bash
npm install @opentelemetry/api @opentelemetry/sdk-node \
  @opentelemetry/exporter-trace-otlp-http
```

### Configure tracing

```javascript
const { NodeSDK } = require('@opentelemetry/sdk-node');
const { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');
const { Resource } = require('@opentelemetry/resources');
const { ATTR_SERVICE_NAME } = require('@opentelemetry/semantic-conventions');

const sdk = new NodeSDK({
  resource: new Resource({
    [ATTR_SERVICE_NAME]: 'my-node-service',
  }),
  traceExporter: new OTLPTraceExporter({
    url: 'http://localhost:5100/v1/traces',
  }),
});

sdk.start();
```

## AI/LLM Applications

For AI applications using `gen_ai.*` semantic conventions:

```csharp
using var activity = s_activitySource.StartActivity("chat");

// Set gen_ai attributes (OTel v1.39.0 semantic conventions)
activity?.SetTag("gen_ai.system", "openai");
activity?.SetTag("gen_ai.request.model", "gpt-4");
activity?.SetTag("gen_ai.response.model", "gpt-4-0613");
activity?.SetTag("gen_ai.usage.input_tokens", 150);
activity?.SetTag("gen_ai.usage.output_tokens", 50);

// Make your LLM call here

activity?.SetStatus(ActivityStatusCode.Ok);
```

<Warning>
  Always set `gen_ai.system` to identify the AI provider. qyl uses this to categorize and filter AI-specific telemetry.
</Warning>

## Verifying Instrumentation

After instrumenting your application:

1. Start qyl collector: `dotnet run --project src/qyl.collector`
2. Run your instrumented application
3. Open dashboard at `http://localhost:5173`
4. You should see traces appearing in real-time

## Troubleshooting

### No traces appearing

- Verify the collector is running on port 5100
- Check your OTLP endpoint URL includes the correct path
- Ensure no firewall is blocking the connection
- Check collector logs for ingestion errors

### Missing attributes

- Verify you're using the correct attribute names per OTel semantic conventions
- Check that attributes are set before the span ends
